# -*- coding: utf-8 -*-
"""Procurement Strategy Optimization .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gXlLmlCB8URvw1tWvP7X0fji8PNc3ZEW
"""

!pip uninstall gensim
!pip uninstall pyLDAvis
!pip uninstall spacy
!pip uninstall numpy

!pip install gensim==4.3.2
!pip install pyLDAvis==3.4.1
!pip install spacy==3.6.1
!pip install --upgrade numpy==1.24.4
# !pip install --upgrade numpy==1.24.3

import pandas as pd
import spacy
from gensim import corpora, models
from gensim.models import CoherenceModel
from google.colab import drive
drive.mount('/content/drive')

# File paths for each dataset
business_file_path = '/content/drive/MyDrive/Colab Notebooks/CIS 509/yelp_dataset/yelp_academic_dataset_business.json'
review_file_path = '/content/drive/MyDrive/Colab Notebooks/CIS 509/yelp_dataset/yelp_academic_dataset_review.json'
user_file_path = '/content/drive/MyDrive/Colab Notebooks/CIS 509/yelp_dataset/yelp_academic_dataset_user.json'
checkin_file_path = '/content/drive/MyDrive/Colab Notebooks/CIS 509/yelp_dataset/yelp_academic_dataset_checkin.json'
tip_file_path = '/content/drive/MyDrive/Colab Notebooks/CIS 509/yelp_dataset/yelp_academic_dataset_tip.json'

# Reading data
business_df = pd.read_json(business_file_path, lines=True)
review_df = pd.read_json(review_file_path, lines=True, nrows=1000)
user_df = pd.read_json(user_file_path, lines=True, nrows=1000)
checkin_df = pd.read_json(checkin_file_path, lines=True, nrows=1000)
tip_df = pd.read_json(tip_file_path, lines=True, nrows=1000)

# Writing data
business_df.to_csv('business_output.csv', index=False)
review_df.to_csv('review_output.csv', index=False)
user_df.to_csv('user_output.csv', index=False)
checkin_df.to_csv('checkin_output.csv', index=False)
tip_df.to_csv('tip_output.csv', index=False)

# Merge review_df with business_df on business_id
merged_df = pd.merge(review_df, business_df, on='business_id', how='left')

# Merge user_df with merged_df on user_id
merged_df = pd.merge(merged_df, user_df, on='user_id', how='left')

# Optionally, merge checkin_df and tip_df if they contain relevant information
# merged_df = pd.merge(merged_df, checkin_df, on='business_id', how='left')
# merged_df = pd.merge(merged_df, tip_df, on=['user_id', 'business_id'], how='left')

# Display the merged dataframe
print(merged_df.head())

"""**Sentiment Analysis**"""

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')  # Download the VADER lexicon for sentiment analysis

# Initialize the Sentiment Intensity Analyzer
sia = SentimentIntensityAnalyzer()

# Function to get sentiment score
def get_sentiment_score(text):
    return sia.polarity_scores(text)['compound']

# Apply sentiment analysis to the 'text' column in the merged dataframe
merged_df['sentiment_score'] = merged_df['text'].apply(get_sentiment_score)

# Categorize sentiment based on the sentiment score
def categorize_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

# Apply sentiment categorization to create a new column 'sentiment'
merged_df['sentiment'] = merged_df['sentiment_score'].apply(categorize_sentiment)

# Display the first few rows of the dataframe with sentiment scores and categories
print(merged_df[['text', 'sentiment_score', 'sentiment']].head())

"""Categorization of Sentiment"""

# Function to categorize sentiment
def categorize_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

# Apply sentiment categorization to create a new column 'sentiment_category'
merged_df['sentiment_category'] = merged_df['sentiment_score'].apply(categorize_sentiment)

# Display the first few rows of the dataframe with sentiment categories
print(merged_df[['text', 'sentiment_score', 'sentiment_category']].head())

pip install -U spacy

import spacy
from collections import Counter

# Load the English language model in spaCy
nlp = spacy.load("en_core_web_sm")

# Define function to preprocess text
def preprocess_text(text):
    # Tokenize the text and remove stop words, punctuation, and lemmatize words
    doc = nlp(text)
    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]
    return tokens

# Define function to extract key themes or topics from reviews
def extract_topics(text):
    # Preprocess text
    tokens = preprocess_text(text)
    # Identify key themes or topics
    topics = [word for word in tokens if word in ['quality', 'delivery', 'price', 'service']]
    return topics

# Apply sentiment analysis to the 'text' column in the merged dataframe
merged_df['sentiment_score'] = merged_df['text'].apply(get_sentiment_score)

# Apply sentiment categorization to create a new column 'sentiment'
merged_df['sentiment'] = merged_df['sentiment_score'].apply(categorize_sentiment)

# Apply topic extraction to the 'text' column in the merged dataframe
merged_df['topics'] = merged_df['text'].apply(extract_topics)

# Count the occurrences of each topic
topic_counts = Counter(topic for topics in merged_df['topics'] for topic in topics)

# Display the counts of each topic
print("Counts of key themes or topics:")
for topic, count in topic_counts.items():
    print(f"{topic}: {count}")

# Print the list of businesses with positive sentiment
print("Businesses with positive sentiment scores:")
for business_id in positive_businesses:
    print(f"- Business ID: {business_id}")

"""Optimization Strategies"""

# Calculate average sentiment score for reviews mentioning delivery
delivery_sentiment_avg = merged_df[merged_df['text'].str.contains('delivery', case=False)]['sentiment_score'].mean()

# If average sentiment score for delivery-related reviews is below a certain threshold, consider optimizing the supply chain
if delivery_sentiment_avg < -0.1:
    print("Negative sentiment detected regarding delivery time. Consider optimizing the supply chain to improve delivery efficiency.")

# Identify suppliers or products with positive sentiment to consider increasing procurement from those sources
# For example, if positive sentiment is associated with certain suppliers or products

# Group reviews by business_id and calculate average sentiment score
business_sentiment_avg = merged_df.groupby('business_id')['sentiment_score'].mean()

# Identify businesses with consistently positive sentiment scores
positive_businesses = business_sentiment_avg[business_sentiment_avg > 0.1].index.tolist()

# Print the list of businesses with positive sentiment
print("Businesses with positive sentiment scores:")
for business_id in positive_businesses:
    print(f"- Business ID: {business_id}")

# Analyze patterns in reviews to identify areas where procurement strategies can be adjusted
# For example, analyze common themes or topics mentioned in reviews related to procurement

# Count the occurrences of each topic in the reviews
topic_counts = Counter(topic for topics in merged_df['topics'] for topic in topics)

# Print the counts of each topic
print("Counts of key themes or topics in reviews:")
for topic, count in topic_counts.items():
    print(f"{topic}: {count}")

# Based on the analysis of common themes or topics, adjust procurement strategies as needed
# For example, if 'quality' is frequently mentioned, focus on improving product quality from suppliers

"""We analyze common themes or topics mentioned in reviews related to procurement and suggest adjusting procurement strategies accordingly. For example, if 'quality' is frequently mentioned, we might focus on improving product quality from suppliers.
This code is helpful because it provides a systematic approach to analyzing sentiment data from customer reviews and using that analysis to make informed decisions about supply chain optimization and procurement strategies. By identifying areas of improvement based on sentiment analysis, businesses can better understand customer needs and preferences, ultimately leading to improved customer satisfaction and business performance.
"""

